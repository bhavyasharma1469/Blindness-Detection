{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Miscelaneous.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t\n",
    "import cv2\n",
    "import warnings\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Sklearn utils.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Keras.\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import DenseNet121\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "PATH = '../input/'\n",
    "PATH_APTOS = PATH + 'aptos2019-blindness-detection/'\n",
    "PATH_2015 = PATH + 'retinopathy-train-2015/rescaled_train_896/'\n",
    "densenet_weights_path = PATH + 'densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "PATH_AUGM = '/data_augm/'\n",
    "HEIGHT, WIDTH = 256, 256\n",
    "RANDOM_STATE = 974\n",
    "VERBOSE = True\n",
    "BATCH_SIZE = 32\n",
    "DATA_AUGM = True\n",
    "DATA_AUGM_FACTOR = 1\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aptos = pd.read_csv(PATH_APTOS + 'train.csv')\n",
    "df_aptos.rename(index=str, columns={\"id_code\": \"id_code_aptos\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = pd.read_csv(PATH_2015 + 'trainLabels.csv')\n",
    "df_2015.rename(index=str, columns={\"image\": \"id_code_2015\", \"level\": \"diagnosis\"}, inplace=True)\n",
    "df_2015 = df_2015.drop(df_2015[df_2015['diagnosis'] == 0].sample(frac=0.8).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_aptos.append(df_2015)\n",
    "df[\"data_augm\"] = np.nan\n",
    "if VERBOSE:\n",
    "    display(df.head())\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    plt.hist(df.diagnosis, bins=[-0.2, 0.2, 0.8, 1.2, 1.8, 2.2, 2.8, 3.2, 3.8, 4.2])\n",
    "    plt.xlabel(\"Severity of Diabetic Retinopathy\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagePreprocessing(image, normalize=True):\n",
    "    # Cutting black border.\n",
    "    row, col = image.shape[0], image.shape[1]\n",
    "    center_row, center_col = row // 2, col // 2\n",
    "    x_left, x_right, y_top, y_bot = 0, col, 0, row\n",
    "    while image[center_row, x_left:x_left + 10].mean().max() <= 10  and x_left < col:\n",
    "        x_left += 1\n",
    "    while image[center_row, x_right - 10:x_right].mean().max() <= 10 and x_right > 0:\n",
    "        x_right -= 1\n",
    "    while image[y_top:y_top + 10, center_col].mean().max() <= 10 and y_top < row:\n",
    "        y_top += 1\n",
    "    while image[y_bot - 10:y_bot, center_col].mean().max() <= 10 and y_bot > 0:\n",
    "        y_bot -= 1\n",
    "    if y_top < y_bot and x_left < x_right and y_bot - y_top > 0.6 * row and x_right - x_left > 0.6 * col:\n",
    "        image = image[y_top:y_bot, x_left:x_right]\n",
    "\n",
    "    # Cutting to remove black corner.\n",
    "    row, col = image.shape[0], image.shape[1]\n",
    "    top_left_x, top_left_y = 0, 0\n",
    "    while image[0, top_left_x:top_left_x + 10].mean().max() <= 10  and top_left_x < col:\n",
    "        top_left_x += 1\n",
    "    while image[top_left_y:top_left_y + 10, 0].mean().max() <= 10  and top_left_y < row:\n",
    "        top_left_y += 1\n",
    "    if 2 * np.abs(top_left_y - top_left_x) / (top_left_y + top_left_x) > 0.85 :\n",
    "        crop_left_right = int(0.5 * top_left_x)\n",
    "        if crop_left_right < 0.3 * col:\n",
    "            image = image[:, crop_left_right:col - crop_left_right]\n",
    "    else:\n",
    "        crop = int(0.15 * (top_left_x + top_left_y) / 2)\n",
    "        if crop < 0.3 * col and crop < 0.3 * row:\n",
    "            image = image[crop:row - crop, crop:col - crop]\n",
    "    \n",
    "    # Resizing image.\n",
    "    image = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    \n",
    "    # Applying GaussianBlur.\n",
    "    blurred = cv2.blur(image, ksize=(int(WIDTH / 6), int(HEIGHT / 6)))\n",
    "    image = cv2.addWeighted(image, 4, blurred, -4, 128)\n",
    "    \n",
    "    try:\n",
    "        if normalize:\n",
    "            image = image / 255\n",
    "            image -= image.mean()\n",
    "            return image\n",
    "        else:\n",
    "            return image\n",
    "    except:\n",
    "        return np.zeros((WIDTH, HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImage(row, train=True, resize=False):\n",
    "    image = None\n",
    "    if not train:\n",
    "        image = cv2.imread('{}test_images/{}.png'.format(PATH_APTOS, row.id_code))\n",
    "    elif not pd.isnull(row.data_augm):\n",
    "        image = cv2.imread(row.data_augm)\n",
    "    elif not pd.isnull(row.id_code_aptos):\n",
    "        image = cv2.imread('{}train_images/{}.png'.format(PATH_APTOS, row.id_code_aptos))\n",
    "    elif not pd.isnull(row.id_code_2015):\n",
    "        image = cv2.imread('{}rescaled_train_896/{}.png'.format(PATH_2015, row.id_code_2015))\n",
    "    else:\n",
    "        print(\"[Error] Could not open the image. Log: {}\".format(row))\n",
    "    if resize and not image is None:\n",
    "        return cv2.resize(image, (WIDTH, HEIGHT))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    nb_row = 4\n",
    "    nb_col = 6\n",
    "    nb = 1\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    for row in df.itertuples():\n",
    "        if nb > nb_col * nb_row:\n",
    "            break\n",
    "        plt.subplot(nb_row, nb_col, nb)\n",
    "        plt.imshow(cv2.cvtColor(imagePreprocessing(openImage(row), normalize=False), cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Diagnosed {}'.format(row.diagnosis))\n",
    "        nb += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaGenerator():\n",
    "    def __init__(self, image_df, batch_size, train=True):\n",
    "        self.image_df = image_df\n",
    "        self.batch_size = batch_size\n",
    "        self.train = train\n",
    "        self.step_per_epoch = len(self.image_df) // self.batch_size\n",
    "        self.step_per_pred = 1 + (len(self.image_df) - 1) // self.batch_size\n",
    "    def getGenerator(self):\n",
    "        while True:\n",
    "            for idx in range(self.step_per_epoch):\n",
    "                batch_x = np.array([imagePreprocessing(openImage(row)) for row in self.image_df[idx * self.batch_size:(idx + 1) * self.batch_size].itertuples()])\n",
    "                batch_y_cat= to_categorical([row.diagnosis for row in self.image_df[idx * self.batch_size:(idx + 1) * self.batch_size].itertuples()], num_classes=5)\n",
    "                batch_y = np.empty(batch_y_cat.shape, dtype=batch_y_cat.dtype)\n",
    "                batch_y[:, 4] = batch_y_cat[:, 4]\n",
    "                for i in range(3, -1, -1):\n",
    "                    batch_y[:, i] = np.logical_or(batch_y_cat[:, i], batch_y[:, i+1])\n",
    "                yield batch_x, batch_y\n",
    "    def getInputGenerator(self):\n",
    "        for idx in range(self.step_per_pred + 1):\n",
    "            yield np.array([imagePreprocessing(openImage(row, self.train)) for row in self.image_df[idx * self.batch_size:min((idx + 1) * self.batch_size, len(self.image_df))].itertuples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_AUGM:\n",
    "    shutil.rmtree(PATH_AUGM, ignore_errors=True, onerror=None)\n",
    "    shutil.os.mkdir(PATH_AUGM)\n",
    "    df = shuffle(df, random_state=RANDOM_STATE)\n",
    "    max_size = int(df.diagnosis.value_counts().max() * DATA_AUGM_FACTOR)\n",
    "    for diag in range(5):\n",
    "        shutil.rmtree('{}diag_{}'.format(PATH_AUGM, diag), ignore_errors=True, onerror=None)\n",
    "        shutil.os.mkdir('{}diag_{}'.format(PATH_AUGM, diag))\n",
    "        diag_df = df[df.diagnosis == diag]\n",
    "        size = len(diag_df)\n",
    "        to_create = max_size - size\n",
    "        augm_per_img = max(to_create // size, 1)\n",
    "        while to_create > 0:\n",
    "            for row in diag_df.itertuples():\n",
    "                if to_create < 0:\n",
    "                    break\n",
    "                image = np.expand_dims(cv2.cvtColor(openImage(row, resize=True), cv2.COLOR_BGR2RGB), 0)\n",
    "                data_generator = ImageDataGenerator(rotation_range=360, vertical_flip=True, horizontal_flip=True, zoom_range=0.1)\n",
    "                data_generator.fit(image)\n",
    "                id_code = row.id_code_aptos if not pd.isnull(row.id_code_aptos) else row.id_code_2015\n",
    "                for x, val in zip(data_generator.flow(image, save_to_dir='{}diag_{}'.format(PATH_AUGM, diag), \n",
    "                                                      save_prefix=id_code, save_format='png'), \n",
    "                                  range(augm_per_img - 1)):\n",
    "                    pass\n",
    "                to_create -= augm_per_img\n",
    "    for diag in range(5):\n",
    "        images = np.array(os.listdir(\"{}diag_{}\".format(PATH_AUGM, diag)))\n",
    "        for image in images:#diagnosis\tid_code_2015\tid_code_aptos\tdata_augm\n",
    "            df = df.append(pd.DataFrame([[diag, np.nan, np.nan, \"{}diag_{}/{}\".format(PATH_AUGM, diag, image)]], columns=df.columns))\n",
    "    df = shuffle(df, random_state=RANDOM_STATE)\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    nb_row = 4\n",
    "    nb_col = 6\n",
    "    nb = 1\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    for row in df.itertuples():\n",
    "        if nb > nb_col * nb_row:\n",
    "            break\n",
    "        plt.subplot(nb_row, nb_col, nb)\n",
    "        plt.imshow(cv2.cvtColor(imagePreprocessing(openImage(row), normalize=False), cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Diagnosed {}'.format(row.diagnosis))\n",
    "        nb += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    plt.hist(df.diagnosis, bins=[-0.2, 0.2, 0.8, 1.2, 1.8, 2.2, 2.8, 3.2, 3.8, 4.2])\n",
    "    plt.xlabel(\"Severity of Diabetic Retinopathy\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_df, test_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "if VERBOSE:\n",
    "    print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.005\n",
    "EPOCHS = 3\n",
    "PATIENCE = 6\n",
    "LR_PATIENCE =6 \n",
    "VALIDATION_GENERATOR = RetinaGenerator(val_df, BATCH_SIZE)\n",
    "TRAINING_GENERATOR = RetinaGenerator(train_df, BATCH_SIZE)\n",
    "ALL_GENERATOR = RetinaGenerator(df, BATCH_SIZE)\n",
    "STEPS_PER_EPOCH = TRAINING_GENERATOR.step_per_epoch\n",
    "VALIDATION_STEPS = VALIDATION_GENERATOR.step_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visible = Input(shape=(HEIGHT, WIDTH, 3))\n",
    "densenet = DenseNet121(include_top=False,\n",
    "                 weights=None,\n",
    "                 input_tensor=visible)\n",
    "densenet.load_weights(densenet_weights_path)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(densenet)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "    \n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizers.Adam(lr=0.00005),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.SGD(lr=LEARNING_RATE, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "Callbacks=[EarlyStopping(patience=PATIENCE, restore_best_weights=True), \n",
    "           ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=VERBOSE)]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    H = model.fit_generator(generator=TRAINING_GENERATOR.getGenerator(),\n",
    "                            validation_data=VALIDATION_GENERATOR.getGenerator(),\n",
    "                            steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                            validation_steps=VALIDATION_STEPS,\n",
    "                            epochs=EPOCHS,\n",
    "                            callbacks=Callbacks,\n",
    "                            verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "\n",
    "if VERBOSE:\n",
    "    TEST_GENERATOR = RetinaGenerator(test_df, BATCH_SIZE)\n",
    "    STEPS = TEST_GENERATOR.step_per_pred\n",
    "    Y_pred = (model.predict_generator(TEST_GENERATOR.getInputGenerator(), steps=STEPS) > 0.5).sum(axis=1) - 1\n",
    "    Y_test = np.array(test_df.diagnosis)\n",
    "    print(\"Average absolute distance is: {:.2f}\".format(np.abs(Y_pred - Y_test).mean()))\n",
    "    display(confusion_matrix(Y_test, Y_pred))\n",
    "    print(\"Accuracy Score:\" + str(accuracy_score(Y_test, Y_pred)))\n",
    "    print(\"Cohen Kappa Score:\" + str(cohen_kappa_score(Y_test, Y_pred, weights='quadratic')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = ALL_GENERATOR.step_per_pred\n",
    "Y_pred = model.predict_generator(ALL_GENERATOR.getInputGenerator(), steps=STEPS)\n",
    "Y_true = to_categorical(np.array(df.diagnosis), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_model = Sequential()\n",
    "post_model.add(Dense(5, input_dim=5, activation='relu'))\n",
    "post_model.add(Dense(5, activation='softmax'))\n",
    "post_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "opt = optimizers.SGD(lr=LEARNING_RATE, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "Callbacks=[EarlyStopping(patience=PATIENCE, restore_best_weights=True), \n",
    "           ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=LR_PATIENCE, verbose=VERBOSE)]\n",
    "with tf.device('/device:GPU:0'):\n",
    "    H = post_model.fit(Y_pred, Y_true, batch_size=10, epochs=10, verbose=VERBOSE )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(PATH_APTOS + 'test.csv')\n",
    "if VERBOSE:\n",
    "    print(sub_df.shape)\n",
    "    display(sub_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB_GENERATOR = RetinaGenerator(sub_df, BATCH_SIZE, False)\n",
    "STEPS = SUB_GENERATOR.step_per_pred\n",
    "Y_sub_preview = model.predict_generator(SUB_GENERATOR.getInputGenerator(), steps=STEPS)\n",
    "Y_sub_cat = post_model.predict(Y_sub_preview)\n",
    "Y_sub = np.argmax(Y_sub_cat, axis=1)\n",
    "#Y_sub = np.argmax(model.predict_generator(SUB_GENERATOR.getInputGenerator(), steps=STEPS), axis=1)\n",
    "if VERBOSE:\n",
    "    print(Y_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['diagnosis'] = Y_sub\n",
    "if VERBOSE:\n",
    "    print(sub_df.shape)\n",
    "    display(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERBOSE:\n",
    "    nb_row = 4\n",
    "    nb_col = 6\n",
    "    nb = 1\n",
    "    plt.figure(figsize=(25, 15))\n",
    "    for row in sub_df.itertuples():\n",
    "        if nb > nb_col * nb_row:\n",
    "            break\n",
    "        plt.subplot(nb_row, nb_col, nb)\n",
    "        plt.imshow(cv2.cvtColor(imagePreprocessing(openImage(row, False), normalize=False), cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Diagnosed {}'.format(row.diagnosis))\n",
    "        nb += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')\n",
    "post_model.save('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
